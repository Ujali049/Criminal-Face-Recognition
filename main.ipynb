{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "# TO connect with anvil server and import media and tables from anvil \n",
    "\n",
    "import anvil.server\n",
    "anvil.server.connect(\"MPDLFTJHTQIFU5EXLAHYDVEW-Q4MVKUCLVQXKOMRJ\")\n",
    "import anvil.media\n",
    "from anvil.tables import app_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries for face recognition\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating global arrays for storing criminal id, known names and encoding of those known named faces from database stored\n",
    "# on anvil server\n",
    "\n",
    "criminal_id=[]\n",
    "known_name=[]\n",
    "known_face_encoding=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and storing criminal id, criminal names and their face encodings from database stored on anvil server \n",
    "\n",
    "for row in app_tables.criminal_record.search():     #accessing rows via search()\n",
    "    criminal_id.append(row['criminal_id'])\n",
    "    known_name.append(row['name'])\n",
    "    with anvil.media.TempFile(row['image']) as filename:\n",
    "        image=face_recognition.load_image_file(filename)\n",
    "        image_encoding=face_recognition.face_encodings(image)[0]\n",
    "        known_face_encoding.append(image_encoding)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function called when new criminal data added in database to append new criminal'd id,name and face encoding in the above\n",
    "# enlisted global arrays\n",
    "\n",
    "@anvil.server.callable\n",
    "def add_in(name,c_id,file):\n",
    "    \n",
    "    criminal_id.append(c_id)\n",
    "    known_name.append(name)\n",
    "    \n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        file=face_recognition.load_image_file(filename)\n",
    "        image_encoding=face_recognition.face_encodings(file)[0]\n",
    "        known_face_encoding.append(image_encoding)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check whether the uploaded image of the person on the website matches with the faces of the criminals stored in \n",
    "# database and return its name and criminal id if found else return not found if face doesnt match with any criminal and \n",
    "# just in case if no face gets detected on the uploaded images it will return No face detected so that user can load another\n",
    "# image of the person to check.\n",
    "\n",
    "@anvil.server.callable\n",
    "def search(file):\n",
    "    name=\"Unknown, Not in database.\"\n",
    "    c_id=\"Null\"\n",
    "    \n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    \n",
    "    face_names = []\n",
    "    face_id=[]\n",
    "    \n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        file=face_recognition.load_image_file(filename)\n",
    "        \n",
    "    small_file = cv2.resize(file, (0, 0), fx=0.25, fy=0.25)\n",
    "    try:     # if face gets detected\n",
    "        face_encodings=face_recognition.face_encodings(small_file)[0]   \n",
    "\n",
    "    except: # face doesnt gets detected\n",
    "        name = \"No Face detected in the Uploaded Image. Try Uploading Another Image !\"\n",
    "        return name,c_id  # returns from here\n",
    "    \n",
    "  #continues if face gets detected  \n",
    "    matches = face_recognition.compare_faces(known_face_encoding, face_encodings)\n",
    "\n",
    "    face_distances = face_recognition.face_distance(known_face_encoding, face_encodings)\n",
    "    best_match_index = np.argmin(face_distances)\n",
    "    if matches[best_match_index]:\n",
    "        name = known_name[best_match_index]\n",
    "        c_id=criminal_id[best_match_index]\n",
    "            \n",
    "    return name,c_id\n",
    "                \n",
    "            \n",
    "    \n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if face gets detected on the uploaded image then returns its encoding else returns fails. Called while live tracking of \n",
    "# person who may or may not be a criminal \n",
    "\n",
    "@anvil.server.callable\n",
    "def track_encoding(file):\n",
    "   \n",
    "    with anvil.media.TempFile(file) as filename:\n",
    "        file=face_recognition.load_image_file(filename)\n",
    "        \n",
    "    small_file = cv2.resize(file, (0, 0), fx=0.25, fy=0.25)\n",
    "    try:\n",
    "        track_face_encoding=face_recognition.face_encodings(small_file)[0]\n",
    "    except:\n",
    "        track_face_encoding=\"fail\"\n",
    "    return track_face_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does Live streaming and displays detected if uploaded image matches the live streamed persons face else displays unknown \n",
    "# here person may or may not be criminal. This function is used to track down specific person whose image is uploaded\n",
    "\n",
    "@anvil.server.callable\n",
    "def track_criminal(track_face_encoding,stop):\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    \n",
    "    # Get a reference to webcam #0 (the default one)\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        \n",
    "        # Hit 'q' on the keyboard to quit and to release all connections !\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "        # Grab a single frame of video\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if ret: # if frame was returned \n",
    "            \n",
    "            # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "            \n",
    "            # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "            rgb_small_frame = small_frame[:, :, ::-1]\n",
    "            \n",
    "             # Find all the faces and face encodings in the current frame \n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "            for face_encoding in face_encodings:   # iterating over all detected face's encoding\n",
    "                \n",
    "                # See if the face is a match for the known face(s)\n",
    "                matches = face_recognition.compare_faces([track_face_encoding], face_encoding)\n",
    "                name = \"Unknown\"\n",
    "                \n",
    "                # use the known face with the smallest distance to the new face\n",
    "                face_distances = face_recognition.face_distance([track_face_encoding], face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)   # finding index of the minimum distance\n",
    "                if matches[best_match_index]:\n",
    "                    name = \"Detected\"\n",
    "                face_names.append(name)\n",
    "                \n",
    "                # Display the results\n",
    "            for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "\n",
    "                # Draw a box around the face\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (255, 153, 153), 2)\n",
    "\n",
    "                # Draw a label with a name below the face\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (255, 153, 153), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_COMPLEX\n",
    "                cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (53, 255, 153), 1)\n",
    "\n",
    "             # Display the resulting image\n",
    "            cv2.imshow('Video', frame)\n",
    "        else: # if frame doesnt gets returned\n",
    "            break\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displays name and criminal id if the detected faces via live streaming matches the faces in the criminal databse. This \n",
    "# detects every face in the live streamed captured frames and matches then with the faces in the database. \n",
    "\n",
    "@anvil.server.callable\n",
    "def survillence():\n",
    "    \n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    \n",
    "    \n",
    "    face_names = []\n",
    "    face_id=[]\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            video_capture.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "       \n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if ret:\n",
    "           \n",
    "            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "           \n",
    "            rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "            for face_encoding in face_encodings:\n",
    "                matches = face_recognition.compare_faces(known_face_encoding, face_encoding)\n",
    "                name = \"Unknown\"\n",
    "                c_id=\"Null\"\n",
    "\n",
    "                face_distances = face_recognition.face_distance(known_face_encoding, face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name =  known_name[best_match_index]\n",
    "                    c_id = criminal_id[best_match_index]\n",
    "                face_names.append(name)\n",
    "                face_id.append(c_id)\n",
    "                \n",
    "                \n",
    "            for (top, right, bottom, left),name,c_id in zip(face_locations,face_names,face_id):\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (255,51,51), 2)\n",
    "\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (255,51,51), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_PLAIN\n",
    "                text=\"Name =\"+name+\" C_ID = \"+str(c_id)\n",
    "                \n",
    "                cv2.putText(frame,text, (left + 6, bottom - 6), font, 1.0, (0,255,0), 1)\n",
    "\n",
    "            cv2.imshow('Survillence', frame)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
